import streamlit as st

from utils.paths import DATA_DIR
from utils.ui import setup_sidebar, add_back_to_top
from utils.load_file import load_data
from utils.core import (
    clean_data,
    extract_multinational_data,
    create_star_schema,
)

st.set_page_config(page_title="Projeto Super Store", page_icon="üõí", layout="wide")

setup_sidebar()
add_back_to_top()

st.title("üõí Projeto Super Store: Modern Data Stack na Pr√°tica")

CSV_PATH = str(DATA_DIR / "superstore.csv")
WIKI_URL = "https://en.wikipedia.org/wiki/List_of_supermarket_chains"

tabs = st.tabs(["Relat√≥rio do Projeto", "Demo Interativa"])

with tabs[0]:
    # --- CABE√áALHO: O PROBLEMA ---
    c1, c2 = st.columns([2, 1])
    with c1:
        st.subheader("O Desafio de Neg√≥cio")
        st.markdown(
            """
            A **Global Superstore** √© uma gigante do varejo com opera√ß√µes em m√∫ltiplos continentes.
            No entanto, a equipe de analytics enfrentava problemas cr√≠ticos:
            1.  **Silos de Dados**: Vendas em CSVs desconectados do ERP.
            2.  **Cegueira de Mercado**: Falta de dados sobre competidores locais para an√°lise de share.
            3.  **Processos Manuais**: Relat√≥rios levavam dias para serem consolidados.
            """
        )
        st.markdown(
            """
            **A Solu√ß√£o Proposta**:
            Uma arquitetura de dados escal√°vel na nuvem (ELT), integrando dados internos e externos em um Data Warehouse centralizado.
            """
        )

    with c2:
        st.info(
            "**Impacto Gerado**: Redu√ß√£o de 90% no tempo de fechamento de relat√≥rios e vis√£o 360¬∫ competitiva."
        )

        st.success(
            """
            **Stack Tecnol√≥gico:**
            *   üêç **Python** (Pandas, BeautifulSoup)
            *   üóÑÔ∏è **SQL** (Modelagem)
            *   ‚òÅÔ∏è **Google BigQuery** (Data Warehouse)
            """
        )

    # --- ARQUITETURA DO PIPELINE ---
    st.subheader("Arquitetura e Metodologia")

    with st.expander("üü¶ Etapa 1: Extra√ß√£o e Enriquecimento", expanded=True):
        st.markdown(
            """
            *   **Dados Internos**: Ingest√£o de arquivos CSV exportados do ERP legado.
            *   **Dados Externos**: *Web Scraping* da lista de multinacionais da Wikipedia para gerar a dimens√£o `dim_company`.
            """
        )

    with st.expander("üü® Etapa 2: Transforma√ß√£o (Data Quality)", expanded=True):
        st.markdown(
            """
            Processo de limpeza realizado em Python/Pandas:
            1.  **Standardization**: Convers√£o de colunas para *snake_case*.
            2.  **Cleaning**: Remo√ß√£o de espa√ßos em branco em vari√°veis categ√≥ricas.
            3.  **Typos**: Corre√ß√£o manual de categorias com base em frequ√™ncia.
            4.  **Outliers**: An√°lise estat√≠stica de vendas e lucro (identificados 5k+ outliers).
            """
        )

    with st.expander("üüß Etapa 3: Modelagem Dimensional (Star Schema)", expanded=True):
        st.markdown("O modelo final foi desenhado para otimizar consultas de BI.")
        st.markdown("**Tabela Fato**: `fato_vendas` (Granularidade: Item do Pedido).")
        st.markdown(
            """
            **Dimens√µes**:
            *   `dim_tempo`: Calend√°rio fiscal.
            *   `dim_produto`: Hierarquia (Categoria > Sub > Produto).
            *   `dim_cliente`: Vis√£o √∫nica do cliente (CRM).
            *   `dim_localizacao`: Geo-refer√™ncia.
            *   `dim_company`: Dados de mercado (Externo).
            """
        )

    # --- DESTAQUES ---
    st.subheader("Destaques do Projeto")
    st.markdown(
        """
        üåü **Avalia√ß√£o T√©cnica:**
        > *"O projeto apresenta uma execu√ß√£o exemplar... A modelagem em Star Schema foi corretamente projetada e a l√≥gica de atualiza√ß√£o incremental demonstra um n√≠vel avan√ßado de engenharia."*
    """
    )
    st.markdown(
        """
        **Pontos Fortes Identificados:**
        *   ‚úÖ **Pipeline H√≠brido**: Fus√£o eficaz de CSV local + Web Scraping.
        *   ‚úÖ **Documenta√ß√£o**: Rastreabilidade completa das regras de neg√≥cio.
        *   ‚úÖ **Preparado para Escala**: L√≥gica de *Upsert/Merge* j√° desenhada para produ√ß√£o.
        """
    )

    # --- ROADMAP ---
    st.subheader("Pr√≥ximos Passos (Roadmap)")
    st.markdown(
        """
        1.  **Orquestra√ß√£o**: Migrar a execu√ß√£o para **Apache Airflow** (Cloud Composer).
        2.  **Governan√ßa**: Implementar *Data Contracts* e testes automatizados (Great Expectations).
        3.  **Observabilidade**: Adicionar alertas de falha via Slack/Email.
        4.  **CI/CD**: Esteira de deploy automatizada para scripts de ETL.
        """
    )

with tabs[1]:
    st.subheader("Demonstra√ß√£o Interativa do Pipeline")
    st.caption("Experimente o fluxo de dados real executado em mem√≥ria.")

    # Sub-tabs para o fluxo t√©cnico
    subtab_extract, subtab_transform, subtab_model = st.tabs(
        [
            "1. Ingest√£o (Extract)",
            "2. Tratamento (Transform)",
            "3. Modelagem (Star Schema)",
        ]
    )

    # State Init
    if "df_raw" not in st.session_state:
        st.session_state.df_raw = None
    if "df_clean" not in st.session_state:
        st.session_state.df_clean = None
    if "schema" not in st.session_state:
        st.session_state.schema = None
    if "df_wiki" not in st.session_state:
        st.session_state.df_wiki = None

    # --- 2.1 EXTRACT ---
    with subtab_extract:

        st.subheader("Fonte A: Vendas Internas (CSV)")
        st.caption("Simula√ß√£o da extra√ß√£o do ERP (40k+ linhas).")
        df_raw, msg = load_data(CSV_PATH)
        if df_raw is not None:
            st.session_state.df_raw = df_raw
            st.dataframe(df_raw.head(), use_container_width=True)
            st.success(f"‚úÖ Extra√≠do com sucesso: {len(df_raw):,} registros.")
        else:
            st.error(msg)

        st.subheader("Fonte B: Padr√µes de Mercado (Web)")
        st.caption(f"Scraping em tempo real de: {WIKI_URL}")
        if st.button("üîÑ Executar Scraping"):
            with st.spinner("Acessando Wikipedia..."):
                df_wiki, msg = extract_multinational_data(WIKI_URL)
                if df_wiki is not None:
                    st.session_state.df_wiki = df_wiki
                    st.dataframe(df_wiki.head(), use_container_width=True)
                    st.success(
                        f"‚úÖ Enriquecimento: {len(df_wiki)} multinacionais identificadas."
                    )
                else:
                    st.error(msg)
        elif st.session_state.df_wiki is not None:
            st.dataframe(st.session_state.df_wiki.head(), use_container_width=True)
            st.success("Dados carregados da mem√≥ria.")

    # --- 2.2 TRANSFORM ---
    with subtab_transform:
        st.subheader("Engine de Tratamento de Dados")
        if st.session_state.df_raw is not None:
            st.markdown("**Regras de Qualidade Aplicadas:**")
            st.code(
                """
1. Sanitiza√ß√£o de Nomes de Coluna (Standardization)
2. Deduplica√ß√£o de Registros (Idempot√™ncia)
3. Tipagem Forte (Schema Enforcement)
4. Tratamento de Nulos (Data Quality)""",
                language="markdown",
            )

            if st.button("‚ñ∂Ô∏è Rodar Pipeline de Limpeza"):
                df_clean = clean_data(st.session_state.df_raw.copy())
                st.session_state.df_clean = df_clean
                st.success(f"Dados processados! Linhas v√°lidas: {len(df_clean)}")

            if st.session_state.df_clean is not None:
                st.dataframe(st.session_state.df_clean.head(), use_container_width=True)
        else:
            st.warning("Aguardando Ingest√£o dos dados na etapa anterior.")

    # --- 2.3 MODEL ---
    with subtab_model:
        st.subheader("Modelagem Dimensional (Analytics Ready)")

        col = st.columns(2)

        col[0].markdown(
            "Transforma√ß√£o para **Star Schema** para otimiza√ß√£o de performance no Power BI."
        )

        col[1].markdown(
            """
            **Entidades Geradas:**
            -   üîµ **Fato Vendas**: Transacional
            -   üü° **Dim Tempo**: Calend√°rio
            -   üü° **Dim Produto**: Cat√°logo
            -   üü° **Dim Cliente**: CRM
            -   üü° **Dim Local**: Geo
            """
        )

        if st.session_state.df_clean is not None:
            if col[0].button("üî® Construir Modelo Dimensional"):
                schema = create_star_schema(st.session_state.df_clean)
                st.session_state.schema = schema
                col[0].success("Tabelas geradas em mem√≥ria!")
        else:
            col[0].warning(
                "‚ö†Ô∏è Por favor, execute as etapas 1 (Ingest√£o) e 2 (Tratamento) antes de prosseguir."
            )

        if st.session_state.schema:
            table_list = list(st.session_state.schema.keys())

            # Prioridade de Sele√ß√£o: fato_vendas
            default_index = 0
            if "fato_vendas" in table_list:
                default_index = table_list.index("fato_vendas")

            sel_table = st.selectbox(
                "Inspecionar Tabela Resultante (Gold Layer):",
                table_list,
                index=default_index,
            )
            st.dataframe(
                st.session_state.schema[sel_table].head(100),
                use_container_width=True,
            )
        elif st.session_state.df_clean is not None:
            col[0].info("Execute a modelagem para visualizar os dados.")
